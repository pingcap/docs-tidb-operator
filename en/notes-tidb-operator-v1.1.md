---
title: TiDB Operator v1.1 Notes
summary: Learn the important notes for TiDB Operator v1.1.
aliases: ['/docs/tidb-in-kubernetes/dev/notes-tidb-operator-v1.1/']
---

# TiDB Operator v1.1 Notes

This document introduces important notes for TiDB Operator v1.1.

## PingCAP no longer updates or maintains tidb-cluster chart

Since TiDB Operator v1.1.0, PingCAP no longer updates the tidb-cluster chart. The components and features that have been managed using the tidb-cluster chart will be managed in new ways in v1.1. See the following table for details:

| Components/Features | Managements in TiDB Operator v1.1 |
| :--- | :--- |
| TiDB Cluster (PD, TiDB, TiKV) | [TidbCluster CR](https://github.com/pingcap/tidb-operator/blob/master/docs/api-references/docs.md) |
| TiDB Monitor | [TidbMonitor CR](https://github.com/pingcap/tidb-operator/blob/master/manifests/monitor/tidb-monitor.yaml) |
| TiDB Initializer | [TidbInitializer CR](https://github.com/pingcap/tidb-operator/blob/master/manifests/initializer/tidb-initializer.yaml) |
| Scheduled Backup | [BackupSchedule CR](https://github.com/pingcap/tidb-operator/blob/master/manifests/backup/backup-schedule-aws-s3-br.yaml) |
| Pump | [TidbCluster CR](https://github.com/pingcap/tidb-operator/blob/master/docs/api-references/docs.md) |
| Drainer | [tidb-drainer chart](https://github.com/pingcap/tidb-operator/tree/master/charts/tidb-drainer) |
| Importer | [tikv-importer chart](https://github.com/pingcap/tidb-operator/tree/master/charts/tikv-importer) |

- PingCAP will continue releasing new versions of the tidb-cluster chart but will not add new features to it. However, community members can still add new features to it.

- If you have deployed your TiDB cluster by TiDB Operator (v1.0.0 <= version < v1.1), after TiDB Operator is upgraded to v1.1, you can still upgrade and manage your TiDB cluster using the tidb-cluster chart v1.1.

## Switch the components and features managed by tidb-cluster chart to services fully supported by TiDB Operator v1.1

In TiDB Operator v1.1, you can still manage your cluster using Helm and the tidb-cluster chart. Although new features will not be added to the tidb-cluster chart, you can contribute new features to the tidb-cluster chart by yourself, or switch to services that are fully supported by TiDB Operator v1.1.

This section describes how to switch your components and features to services in TiBD Operator v1.1.

### Discovery

The Discovery service is generated by TiDB Operator automatically, so you do not need to configure it on your own.

### PD/TiDB/TiKV

In tidb-cluster chart, the configurations of PD, TiDB, and TiKV are rendered into ConfigMap by Helm.

Since TiDB Operator v1.1, you can configure TiDB, TiKV, and PD directly in TidbCluster Custom Resource (CR). For configuration details, refer to [Configure a TiDB Cluster using TidbCluster](configure-a-tidb-cluster.md).

> **Note:**
>
> The way TiDB Operator renders configurations is different from that of Helm. If you migrate configurations from `tidb-cluster chart values.yaml` to CR, the corresponding components might be rolling updated.

### Monitor

To create the TidbMonitor CR and manage the Monitor component, refer to [Monitor a TiDB Cluster using TidbMonitor](monitor-using-tidbmonitor.md).

> **Note:**
>
> * The `metadata.name` in the TidbMonitor CR must be consistent with the name of the TidbCluster CR in the cluster.
> * The way TiDB Operator renders resources is different from that of Helm. If you migrate configurations from `tidb-cluster chart values.yaml` to TidbMonitor CR, the Monitor component might be rolling updated.

### Initializer

- If the initialization job is executed before TiDB Operator is upgraded to v1.1, the initialization job does not need to be migrated from the tidb-cluster chart to the TidbInitializer CR.

- If the initialization job is not executed before TiDB Operator is upgraded to v1.1, and the password for the TiDB root user is not modified, you need to initialize your cluster after upgrading to TiDB Operator v1.1. For details, refer to [Initialize a TiDB Cluster in Kubernetes](initialize-a-cluster.md).

### Pump

After TiDB Operator is upgraded to v1.1, you can modify the TidbCluster CR and add the configuration of Pump. You can then manage the Pump component using TidbCluster CR.

``` yaml
spec
  ...
  pump:
    baseImage: pingcap/tidb-binlog
    version: v4.0.7
    replicas: 1
    storageClassName: local-storage
    requests:
      storage: 30Gi
    schedulerName: default-scheduler
    config:
      addr: 0.0.0.0:8250
      gc: 7
      heartbeat-interval: 2
```

You can modify `version`, `replicas`, `storageClassName`, `requests.storage`, and other configurations according to the needs of your cluster.

> **Note:**
>
> The way TiDB Operator renders resources is different from that of Helm. If you migrate configurations from `tidb-cluster chart values.yaml` to TidbCluster CR, the Pump component might be rolling updated.

### Scheduled Backup

After TiDB Operator is upgraded to v1.1, you can configure the scheduled full backup using BackupSchedule CR:

- If the TiDB cluster version < v3.1, refer to [Scheduled backup using Dumpling](backup-to-s3.md#scheduled-full-backup-to-s3-compatible-storage)
- If the TiDB cluster version >= v3.1, refer to [Scheduled backup using BR](backup-to-aws-s3-using-br.md#scheduled-full-backup)

> **Note:**
>
> - Currently, with BackupSchedule CR, you can back up data only to S3 and GCS using Dumpling, and back up data to S3 using BR. If you perform the scheduled full backup and send data to local Persistent Volume Claim (PVC) before the upgrade, you cannot switch to the CR management after the upgrade.
> - If you switch to the CR management, to avoid repeated backup, delete the Cronjob of the previous scheduled full backup.

### Drainer

- If Drainer is not deployed before TiDB Operator is upgraded to v1.1, you can deploy Drainer as in [Deploy multiple drainers](deploy-tidb-binlog.md#deploy-drainer).
- If Drainer is already deployed using the tidb-drainer chart before TiDB Operator is upgraded to v1.1, it is recommended to continue managing Drainer using the tidb-drainer chart.
- If Drainer is already deployed using the tidb-cluster chart before TiDB Operator is upgraded to v1.1, it is recommended to manage Drainer using kubectl.

### TiKV Importer

- If TiKV Importer is not deployed before TiDB Operator is upgraded to v1.1, you can deploy TiKV Importer as in [Deploy TiKV Importer](restore-data-using-tidb-lightning.md#deploy-tikv-importer).
- If TiKV Importer is already deployed before TiDB Operator is upgraded to v1.1, it is recommended to manage TiKV Importer using kubectl.

## Switch other components or features managed by chart to services supported by TiDB Operator v1.1

This section describes how to switch other components and features managed by the chart to services in TiBD Operator v1.1.

## Ad-hoc backup

After TiDB Operator is upgraded to v1.1, you can perform backup using the Backup CR. Backup with Dumpling supports full backup, and backup with BR supports both full backup and incremental backup.

- If the TiDB cluster version < v3.1, refer to [Ad-hoc full backup using Dumpling](backup-to-s3.md#ad-hoc-full-backup-to-s3-compatible-storage).
- If the TiDB cluster version >= v3.1, refer to [Ad-hoc backup using BR](backup-to-aws-s3-using-br.md#ad-hoc-backup).

> **Note:**
>
> Currently, with Backup CR, you can back up data only to S3 and GCS using Dumpling or BR. If you perform the scheduled full backup and send data to local Persistent Volume Claim (PVC) before the upgrade, you cannot switch to the CR management after the upgrade.

## Restoration

After the TiDB Operator is upgraded to v1.1, you can restore data using the Restore CR.

- If the TiDB cluster version < v3.1, refer to [Restore Data from S3-Compatible Storage Using TiDB Lightning](restore-from-s3.md).
- If the TiDB cluster version >= v3.1, refer to [Restore Data from S3-Compatible Storage Using BR](restore-from-aws-s3-using-br.md).

> **Note:**
>
> Currently, with Restore CR, you can use TiDB Lightning or BR to restore data from S3 and GCS. If you need to restore the backup data from local Persistent Volume Claim (PVC), you cannot switch to the CR management.
